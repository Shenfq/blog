<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度神经网络原理与实践 | 自然醒的博客</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/favicon.ico">
    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?681a9f14f2db8e622747ef03c33bb367";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
    <meta name="description" content=" ">
    
    <link rel="preload" href="/assets/css/0.styles.a1257572.css" as="style"><link rel="preload" href="/assets/js/app.318ac574.js" as="script"><link rel="preload" href="/assets/js/3.38c624e7.js" as="script"><link rel="preload" href="/assets/js/1.a547ec77.js" as="script"><link rel="preload" href="/assets/js/40.902ba1b5.js" as="script"><link rel="prefetch" href="/assets/js/10.6013c20b.js"><link rel="prefetch" href="/assets/js/11.3d8fc37f.js"><link rel="prefetch" href="/assets/js/12.d356848f.js"><link rel="prefetch" href="/assets/js/13.503aa3ef.js"><link rel="prefetch" href="/assets/js/14.0cc170d7.js"><link rel="prefetch" href="/assets/js/15.80a29d65.js"><link rel="prefetch" href="/assets/js/16.eeef94d5.js"><link rel="prefetch" href="/assets/js/17.473fd739.js"><link rel="prefetch" href="/assets/js/18.7a94ffa7.js"><link rel="prefetch" href="/assets/js/19.1049cfdf.js"><link rel="prefetch" href="/assets/js/20.928b8fee.js"><link rel="prefetch" href="/assets/js/21.8fa143ce.js"><link rel="prefetch" href="/assets/js/22.b094a8de.js"><link rel="prefetch" href="/assets/js/23.9897185b.js"><link rel="prefetch" href="/assets/js/24.12f7413e.js"><link rel="prefetch" href="/assets/js/25.251a0dbc.js"><link rel="prefetch" href="/assets/js/26.bf0e0cf4.js"><link rel="prefetch" href="/assets/js/27.d4dc9aa5.js"><link rel="prefetch" href="/assets/js/28.b67394ce.js"><link rel="prefetch" href="/assets/js/29.2c093fe1.js"><link rel="prefetch" href="/assets/js/30.88baa945.js"><link rel="prefetch" href="/assets/js/31.db871da7.js"><link rel="prefetch" href="/assets/js/32.aca26529.js"><link rel="prefetch" href="/assets/js/33.4355b0d1.js"><link rel="prefetch" href="/assets/js/34.1e25eec3.js"><link rel="prefetch" href="/assets/js/35.33b6be8f.js"><link rel="prefetch" href="/assets/js/36.af8dc1b5.js"><link rel="prefetch" href="/assets/js/37.0a442b7d.js"><link rel="prefetch" href="/assets/js/38.b8932c36.js"><link rel="prefetch" href="/assets/js/39.873ac12b.js"><link rel="prefetch" href="/assets/js/4.22f3476d.js"><link rel="prefetch" href="/assets/js/41.b3a01dd9.js"><link rel="prefetch" href="/assets/js/42.e124f445.js"><link rel="prefetch" href="/assets/js/43.a3cd5e06.js"><link rel="prefetch" href="/assets/js/44.77a9226e.js"><link rel="prefetch" href="/assets/js/45.0c563d44.js"><link rel="prefetch" href="/assets/js/46.abecd608.js"><link rel="prefetch" href="/assets/js/47.945d2559.js"><link rel="prefetch" href="/assets/js/48.96121d35.js"><link rel="prefetch" href="/assets/js/49.b6e988b3.js"><link rel="prefetch" href="/assets/js/5.eb73409d.js"><link rel="prefetch" href="/assets/js/50.51197aa2.js"><link rel="prefetch" href="/assets/js/51.cba93298.js"><link rel="prefetch" href="/assets/js/52.5845bf72.js"><link rel="prefetch" href="/assets/js/53.05e334fd.js"><link rel="prefetch" href="/assets/js/54.730245bb.js"><link rel="prefetch" href="/assets/js/55.fe4f1899.js"><link rel="prefetch" href="/assets/js/56.9fc2cca2.js"><link rel="prefetch" href="/assets/js/57.ba509f83.js"><link rel="prefetch" href="/assets/js/58.e2c3009c.js"><link rel="prefetch" href="/assets/js/59.45cf1f42.js"><link rel="prefetch" href="/assets/js/6.c75b1c30.js"><link rel="prefetch" href="/assets/js/60.cb622813.js"><link rel="prefetch" href="/assets/js/61.77d4b62e.js"><link rel="prefetch" href="/assets/js/62.7acffff4.js"><link rel="prefetch" href="/assets/js/63.a9a1e121.js"><link rel="prefetch" href="/assets/js/64.2952287b.js"><link rel="prefetch" href="/assets/js/65.e46eb76e.js"><link rel="prefetch" href="/assets/js/66.d6579358.js"><link rel="prefetch" href="/assets/js/67.263c1a64.js"><link rel="prefetch" href="/assets/js/68.167b338f.js"><link rel="prefetch" href="/assets/js/69.7cc7de17.js"><link rel="prefetch" href="/assets/js/7.7e6be3ad.js"><link rel="prefetch" href="/assets/js/70.4cd87fd5.js"><link rel="prefetch" href="/assets/js/71.03d8452b.js"><link rel="prefetch" href="/assets/js/72.ed53a810.js"><link rel="prefetch" href="/assets/js/73.9a316584.js"><link rel="prefetch" href="/assets/js/74.fabacaa2.js"><link rel="prefetch" href="/assets/js/75.8d7e3516.js"><link rel="prefetch" href="/assets/js/76.ffbb5827.js"><link rel="prefetch" href="/assets/js/77.a54abacd.js"><link rel="prefetch" href="/assets/js/78.387b274e.js"><link rel="prefetch" href="/assets/js/79.4245741e.js"><link rel="prefetch" href="/assets/js/8.089b1e80.js"><link rel="prefetch" href="/assets/js/80.e7c18fed.js"><link rel="prefetch" href="/assets/js/81.c6465575.js"><link rel="prefetch" href="/assets/js/82.4e0588dd.js"><link rel="prefetch" href="/assets/js/83.846e3dd3.js"><link rel="prefetch" href="/assets/js/84.42030c5b.js"><link rel="prefetch" href="/assets/js/85.eb6c0afb.js"><link rel="prefetch" href="/assets/js/86.b1e4b9b2.js"><link rel="prefetch" href="/assets/js/87.f48ae41b.js"><link rel="prefetch" href="/assets/js/88.84bcc4c7.js"><link rel="prefetch" href="/assets/js/89.c36e2e4e.js"><link rel="prefetch" href="/assets/js/9.a15a624d.js"><link rel="prefetch" href="/assets/js/90.1b535ac6.js"><link rel="prefetch" href="/assets/js/91.643af168.js"><link rel="prefetch" href="/assets/js/92.56bcb90f.js"><link rel="prefetch" href="/assets/js/93.2c179837.js"><link rel="prefetch" href="/assets/js/94.5e1d5354.js"><link rel="prefetch" href="/assets/js/95.1591a73b.js"><link rel="prefetch" href="/assets/js/96.07185bc3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.a1257572.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-5bb33761><div data-v-5bb33761><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-5bb33761 data-v-5bb33761><h3 class="title" data-v-59e6cb88>自然醒的博客</h3> <p class="description" data-v-59e6cb88> </p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2022
      </a></span></div></div> <div class="hide" data-v-5bb33761><header class="navbar" data-v-5bb33761><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">自然醒的博客</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div><div class="nav-item"><a href="/about/" class="nav-link"><i class="iconfont reco-account"></i>
  自我介绍
</a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-5bb33761></div> <aside class="sidebar" data-v-5bb33761><div class="personal-info-wrapper" data-v-1fad0c41 data-v-5bb33761><!----> <!----> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>85</h3> <h6 data-v-1fad0c41>Articles</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>127</h3> <h6 data-v-1fad0c41>Tags</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div><div class="nav-item"><a href="/about/" class="nav-link"><i class="iconfont reco-account"></i>
  自我介绍
</a></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-5bb33761><h3 class="title" data-v-59e6cb88>深度神经网络原理与实践</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2022
      </a></span></div></div> <div data-v-5bb33761><div data-v-5bb33761><main class="page"><section style="display:;"><div class="page-title"><h1 class="title">深度神经网络原理与实践</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>shenfq</span></i> <i class="iconfont reco-date" data-v-8a445198><span data-v-8a445198>3/17/2019</span></i> <!----> <i class="tags iconfont reco-tag" data-v-8a445198><span class="tag-item" data-v-8a445198>机器学习</span><span class="tag-item" data-v-8a445198>深度学习</span><span class="tag-item" data-v-8a445198>神经网络</span></i></div></div> <div class="theme-reco-content content__default"><h2 id="理论基础"><a href="#理论基础" class="header-anchor">#</a> 理论基础</h2> <h3 id="什么是神经网络"><a href="#什么是神经网络" class="header-anchor">#</a> 什么是神经网络</h3> <p>我们知道深度学习是机器学习的一个分支，是一种以人工神经网络为架构，对数据进行表征学习的算法。而深度神经网络又是深度学习的一个分支，它在 wikipedia 上的解释如下：</p> <blockquote><p>深度神经网络（Deep Neural Networks, DNN）是一种判别模型，具备至少一个隐层的神经网络，可以使用反向传播算法进行训练。权重更新可以使用下式进行随机梯度下降法求解。</p></blockquote> <p>首先我们可以知道，深度神经网络是一种判别模型。意思就是已知变量 x ，通过判别模型可以推算出 y。比如机器学习中常用到的案例，通过手写数字，模型推断出手写的是数字几。</p> <p><img src="https://file.shenfq.com/Fjw7fiWg-n1qXji4aX9DUz10Nrqa.png" alt="image"></p> <p>深度神经网络中的“深度”指的是一系列连续的表示层，数据模型中包含了多少层，这就被称为模型的“深度”。通过这些层我们可以对数据进行高层的抽象。如下图所示，深度神级网络由一个输入层，多个（至少一个）隐层，以及一个输出层构成，而且输入层与输出层的数量不一定是对等的。每一层都有若干个神经元，神经元之间有连接权重。</p> <p><img src="https://file.shenfq.com/FuBpmY1q3QeBX22BvqjMUV2ea1U0.png" alt="image"></p> <p>还是上面的案例，识别手写数字，手写的数字要怎么转成输入呢？既然是手写，那么肯定是一张图片，图片由多个像素点组成，这些像素点可以构成一个输入，经过多层神经网络，输出10个数字，这个10个数字就代表了数字 0 ~ 9 的概率。</p> <p><img src="https://file.shenfq.com/FsdJBzIsxftYo9e89lUwU2wlx5O7.png" alt="image"></p> <h3 id="神经元如何输入输出"><a href="#神经元如何输入输出" class="header-anchor">#</a> 神经元如何输入输出</h3> <p>神经网络中的每个神经元都可以看成是一个简单的线性函数，下面我们构造一个简单的三层的神经网络来看看。</p> <p><img src="https://file.shenfq.com/FnQlw8WyQxZ-iszYHdFur7PxwrY0.png" alt="image"></p> <p>如上图所示，n1 可以表示为：</p> <p>$$
n_1 = w_{1,1}x_1 + w_{2,1}x_2 + w_{3,1}x_3 + b
$$</p> <p>其中 $w_{1,1}$ 表示神经元之间的权重，b 为一个常量，作为函数的偏移量。较小的权重可以弱化某个神经元对下一个神经元造成的影响，而较大的权重将放大信号。假设 $w_{1,1}$ 为 0.1，$w_{3,1}$ 为 0.7，那么 x3 对 n1 的影响要大于 x1。你可能会问，为什么每个神经元要与其他所有层的神经元相互连接？</p> <p>这里主要由两个原因：</p> <ol><li>完全连接的形式相对容易的编写成计算机指令。</li> <li>在神经网络训练的过程中会弱化实际上不需要的连接（也就是某些连接权重会慢慢趋近于 0）。</li></ol> <p>实际上通过计算得到 n1 后，其实不能立马用于后面的计算，还需要经过一个激活函数（一般为 sigmod 函数）。</p> <p><img src="https://file.shenfq.com/Fvu_bZlZ1vUg249qL6Rjvox19GXg.png" alt="image"></p> <p><img src="https://file.shenfq.com/Ft059zilmQAlgRWVCl56_DV_MjoB.png" alt="sigmod 函数"></p> <p>其作用主要是引入非线性因素。如果神级网络中只有上面那种线性函数，无论有多少层，结果始终是线性的。</p> <h4 id="实际案例"><a href="#实际案例" class="header-anchor">#</a> 实际案例</h4> <p>为了方便计算，我们构造一个只有两层的神经网络，演示一下具体的计算过程。</p> <p><img src="https://file.shenfq.com/FozUDE0MOGnnoMqGhIOzVlFekc-k.png" alt="image"></p> <p>先通过线性函数求得一个 x 值，再把 x 值带入激活函数，得到 y1 的值。</p> <p>$$
x = w_{1,1}x_1 + w_{2,1}x_2 = (1.0 * 0.9) + (0.5 * 0.3) = 1.05
$$</p> <p>$$
y_1 = 1 / (1 + e ^{-x}) = 1 / (1 + 0.3499) = 0.7408
$$</p> <h3 id="矩阵乘法"><a href="#矩阵乘法" class="header-anchor">#</a> 矩阵乘法</h3> <p>其实上面的计算过程，很容易通过矩阵乘法的方式表示。矩阵这个东西，说简单点就是一个表格，或者一个二维数组。如下图所示，就是一个典型的矩阵。</p> <p><img src="https://file.shenfq.com/Fle6c7tCJeSpI56GXYLhpDvI5F9o.png" alt="image"></p> <p>那么矩阵的乘法可以表示为：</p> <p><img src="https://file.shenfq.com/Fl5i9c6pmYwtkwupgDlppqaA-YsD.png" alt="image"></p> <p>矩阵的乘法通常被成为点乘或者内积。如果我们将矩阵内的数字换成我们神经网络的输入和权重，你会发现原来前面的计算如此简单。</p> <p><img src="https://file.shenfq.com/FvkpHJlq3aCNMqw-plANUCRp3_r-.png" alt="image"></p> <p>获得点积后，只需要代入到激活函数，就能获得输出了。</p> <p><img src="https://file.shenfq.com/Fh7GrdgN0p0Y0Ys5qrcQUxdqVx3N.png" alt="image"></p> <p>通过矩阵计算过程可以表示为：</p> <p>$$
X_{hidden} = W_{input_hidden} · I_{input}</p> <p>O_{hidden} = sigmoid(X_{hidden})
$$</p> <h4 id="实际案例-2"><a href="#实际案例-2" class="header-anchor">#</a> 实际案例</h4> <p>下面通过矩阵来表示一个三层神经网络的计算过程。</p> <p><img src="https://file.shenfq.com/Fipyv33DnVPnwP-GY55JevCWbFOk.png" alt="image"></p> <p>上图只给出了输入层到隐层的计算过程，感兴趣可以自己手动计算下，隐层到输出层的计算过程。隐层到输出层的权重矩阵如下：</p> <p><img src="https://file.shenfq.com/FlAAJfkpy5sVbAfRcFh5SC084ufW.png" alt="image"></p> <h3 id="反向传播"><a href="#反向传播" class="header-anchor">#</a> 反向传播</h3> <p>进过一轮神经网络计算得到输出值，通常与我们实际想要的值是不一致的，这个时候我们会得到一个误差值（误差值就是训练数据给出的正确答案与实际输出值之间的差值）。但是这个误差是多个节点共同作用的结果，我们到底该用何种方式来更新各个连接的权重呢？这个时候我们就需要通过反向传播的方式，求出各个节点的误差值。</p> <p><img src="https://file.shenfq.com/Fs3p0gufO8D59AXgizAwXk4VI3vU.png" alt="image"></p> <p>下面我们代入具体值，进行一次计算。</p> <p><img src="https://file.shenfq.com/Fn2bljmwTC0IIqdAldaMKpv-WQ5N.png" alt="image"></p> <p>上图中可以看到 $e_1$ 的误差值主要由 $w_{1,1}$ 和 $w_{2,1}$ 造成，那么其误差应当分散到两个连接上，可以按照两个连接的权重对误差 $e_1$ 进行分割。</p> <p>$$
e_1 * \frac{w_{1,1}}{w_{1,1} + w_{2,1}} = 0.8 * \frac{2}{2 + 3} = 0.32
$$</p> <p>$$
e_1 * \frac{w_{2,1}}{w_{1,1} + w_{2,1}} = 0.8 * \frac{3}{2 + 3} = 0.48
$$</p> <p>同理对误差 $e_2$ 进行分割，然后把两个连接处的误差值相加，就能得到输出点的前馈节点的误差值。</p> <p><img src="https://file.shenfq.com/FrCafEfslODTYVqrV6pFZaMI-TiG.png" alt="image"></p> <p>然后在按照之前的方法将这个误差传播到前面的层，直到所有节点都能得到自己的误差值，这种方式被成为反向传播。</p> <h4 id="使用矩阵乘法进行反向传播误差"><a href="#使用矩阵乘法进行反向传播误差" class="header-anchor">#</a> 使用矩阵乘法进行反向传播误差</h4> <p>上面如此繁琐的操作，我们也可以通过矩阵的方式进行简化。</p> <p><img src="https://file.shenfq.com/FmYWgu8b1lMgQxEqynXOxxllgaYa.png" alt="image"></p> <p>这个矩阵中还是有麻烦的分数需要处理，那么我们能不能大胆一点，将分母直接做归一化的处理。这么做我们仅仅只是改变了反馈误差的大小，其误差依旧是按照比例来计算的。</p> <p><img src="https://file.shenfq.com/FjD8lHUXF7Ytn9W8YWcnHOUa28-9.png" alt="image"></p> <p><img src="https://file.shenfq.com/FmdzXGU-rU3BCo-Mz3eNvKckP-wE.png" alt="image"></p> <p>仔细观察会发现，与我们之前计算每层的输出值的矩阵点击很像，只是权重矩阵进行翻转，右上方的元素变成了左下方的元素，我们可以称其为转置矩阵，记为 $ w^T $。</p> <p>反向传播误差的矩阵可以简单表示为：</p> <p>$$
error_{hidden} = W^{T}<em>{hidden_output} · error</em>{output}
$$</p> <h3 id="梯度下降"><a href="#梯度下降" class="header-anchor">#</a> 梯度下降</h3> <p>在每个点都得到误差后，我们该按照何种方式来更新权重呢？</p> <p>这个时候就要使用到机器学习中常用的方式：梯度下级。</p> <p><img src="https://file.shenfq.com/FsrJBt8QxtpMcJ2qpJeeTAR0sYTW.png" alt="image"></p> <p>更多细节可以参考我之前写的博客：<a href="https://blog.shenfq.com/2019/01/28/2019/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" target="_blank" rel="noopener noreferrer">梯度下降与线性回归<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>通过不停的训练，我们就能改进神经网络，其本质就是不断地改变权重的大小，减小神经网络输出的误差值。
最后就能够得到一个多层神经网络的模型，通过输入进行有效的预测。</p> <h2 id="实战"><a href="#实战" class="header-anchor">#</a> 实战</h2> <h3 id="环境准备"><a href="#环境准备" class="header-anchor">#</a> 环境准备</h3> <p>首先需要安装 python3 ，直接去 python 官网安装，尽量安装最新版，不推荐安装 python2 。安装好 python 环境之后，然后安装 virtualenv 以及相关依赖。</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># 升级 pip 到最新版本</span>
pip3 <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> pip

<span class="token comment"># 安装 virtualenv ，用于配置虚拟环境</span>
pip3 <span class="token function">install</span> <span class="token parameter variable">--user</span> <span class="token parameter variable">--upgrade</span> virtualenv
</code></pre></div><p>正常情况下，当我们在使用 pip 进行包安装的时候，都是安装的全局包，相当于<code>npm install -g</code>。假如现在有两个项目，项目 A 依赖 simplejson@2 ，项目 B 依赖 simplejson@3，这样我们在一台机器上开发显得有些手足无措。这个时候 virtualenv 就能大展身手了，virtualenv 可以创建一个独立的 python 运行环境，也就是一个沙箱，你甚至可以在 virtualenv 创建的虚拟环境中使用与当前系统不同的 python 版本。</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># 配置虚拟环境</span>
<span class="token builtin class-name">cd</span> ~/ml
virtualenv <span class="token function">env</span>

<span class="token comment"># 启动虚拟环境</span>
<span class="token comment"># linux</span>
<span class="token builtin class-name">source</span> env/bin/activate
<span class="token comment"># windows</span>
./env/Scripts/activate

</code></pre></div><p>启动后，如下</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token punctuation">(</span>env<span class="token punctuation">)</span> λ 
</code></pre></div><p><img src="https://file.shenfq.com/Fn5PT4ZTWJRwwnOIMTRAP6AZV07z.png" alt="image"></p> <p>在虚拟环境下安装所有模块依赖。</p> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token comment"># 安装模块和依赖</span>
<span class="token punctuation">(</span>env<span class="token punctuation">)</span> λ pip3 <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> jupyter matplotlib numpy scipy
</code></pre></div><ul><li><p>jupyter：基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。</p></li> <li><p>numpy：数组计算扩展的包，支持高维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。</p></li> <li><p>scipy：基于numpy的扩展包，它增加的功能包括数值积分、最优化、统计和一些专用函数。</p></li> <li><p>matplotlib：基于numpy的扩展包，提供了丰富的数据绘图工具，主要用于绘制一些统计图形。</p></li> <li><p>scikit-learn：开源的Python机器学习库，它基于Numpy和Scipy，提供了大量用于数据挖掘和分析的工具，包括数据预处理、交叉验证、算法与可视化算法等一系列接口。</p></li></ul> <h4 id="启动-jupyter"><a href="#启动-jupyter" class="header-anchor">#</a> 启动 jupyter</h4> <div class="language- extra-class"><pre class="language-text"><code>jupyter notebook
</code></pre></div><p>jupyter 会在8888端口起一个服务，并自动打开浏览器。</p> <p><img src="https://file.shenfq.com/FoIVlLx4Rsh81RLyGmgZ5r0lyuZe.png" alt="image"></p> <p>通过右上角的new，你就能创建一个项目了。创建项目后，我们很方便的在该页面上进行 python 代码的运行与输出。</p> <p><img src="https://file.shenfq.com/FmSvJC2Uv_plGVynXbzcWsNfeyEV.gif" alt="image"></p> <h4 id="准备数据"><a href="#准备数据" class="header-anchor">#</a> 准备数据</h4> <p>MNIST 是由美国的高中生和美国人口调查局的职员手写数字（0 ~ 9）图片。接下来要做的事情就是让我们的程序学习这些图片的信息，能够识别出输入的图片所代表的数字含义，这听上去好像有点难度，不着急，我们一步步来。</p> <p>这里准备了 MNIST 的训练数据，其中 <code>train_100</code> 为训练数据集，<code>test_10</code> 为测试数据集。在机器学习的过程中，我们一般会将数据集切分成两个，分别为训练集合测试集，一般 80% 的数据进行训练，保留 20% 用于测试。这里因为是 hello world 操作，我们只用 100 个数据进行训练，真实情况下，这种数据量是远远不够的。</p> <ul><li><a href="https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_train_100.csv" target="_blank" rel="noopener noreferrer">mnist_train_100.csv<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://raw.githubusercontent.com/makeyourownneuralnetwork/makeyourownneuralnetwork/master/mnist_dataset/mnist_test_10.csv" target="_blank" rel="noopener noreferrer">mnist_test_10.csv<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>如果想用完整的数据进行训练，可以下载这个 csv 文件。</p> <p><a href="https://pjreddie.com/media/files/mnist_train.csv" target="_blank" rel="noopener noreferrer">https://pjreddie.com/media/files/mnist_train.csv<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h4 id="观察数据"><a href="#观察数据" class="header-anchor">#</a> 观察数据</h4> <p>下载数据后，将 csv （逗号分隔值文件格式）文件放入到 datasets 文件夹，然后使用 python 进行文件的读取。</p> <div class="language-python extra-class"><pre class="language-python"><code>data_file <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;datasets/mnist_train_100.csv&quot;</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
data_list <span class="token operator">=</span> data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># readlines方法用于读取文件的所有行，并返回一个数组</span>
data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token builtin">len</span><span class="token punctuation">(</span>data_list<span class="token punctuation">)</span> <span class="token comment"># 数组长度为100</span>
</code></pre></div><p>打印第一行文本，看看数据的格式是怎么样的</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>data_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>data_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 使用 , 进行分割，将字符串转换为数组</span>
</code></pre></div><p><img src="https://file.shenfq.com/FpwLohSBEtk8nhG2dyGeE91jZwHe.png" alt="image"></p> <p>可以看到一行数据一共有 785 个数据，第一列表示这个手写数的真实值（这个值在机器学习中称为标签），后面的 784 个数据表示一个 28 * 28 的尺寸的像素值，流行的图像处理软件通常用8位表示一个像素，这样总共有256个灰度等级(像素值在0~255 间)，每个等级代表不同的亮度。</p> <p>下面我们导入 numpy 库，对数据进行处理，values[1:] 取出数组的第一位到最后并生成一个新的数组，使用 numpy.asfarray 将数组转为一个浮点类型的 ndarray，然后每一项除以 255 在乘以 9，将每个数字转为 0 ~ 9 的个位数，使用 astype(int) 把每个数再转为 int 类型，最后 reshape((28,28) 可以把数组转为 28 * 28 的二维数组。</p> <p>如果想了解更多 numpy 的资料，可以查看它的<a href="https://www.numpy.org.cn/index.html" target="_blank" rel="noopener noreferrer">文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

values <span class="token operator">=</span> data_list<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>
image_array <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span> <span class="token operator">*</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
</code></pre></div><p><img src="https://file.shenfq.com/FrwDGzwLUk0yEgKOvPPRCykAOJWg.png" alt="image"></p> <p>这样看不够直观，接下来使用 matplotlib ，将像素点一个个画出来。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot
<span class="token operator">%</span>matplotlib inline

matplotlib<span class="token punctuation">.</span>pyplot<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>
    np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    cmap<span class="token operator">=</span><span class="token string">'Greys'</span><span class="token punctuation">,</span> 
    interpolation<span class="token operator">=</span><span class="token string">'None'</span>
<span class="token punctuation">)</span>
</code></pre></div><p><img src="https://file.shenfq.com/FjeF-u3KhHB0ii7ryTNiR1Aji28v.png" alt="image"></p> <h3 id="搭建神经网络"><a href="#搭建神经网络" class="header-anchor">#</a> 搭建神经网络</h3> <p>我们简单勾勒出神经网络的大概样子，至少需要三个函数：</p> <ol><li>初始化函数——设定输入层、隐藏层、输出层节点的数量，随机生成的权重。</li> <li>训练——学习给定的训练样本，调整权重。</li> <li>查询——给定输入，获取预测结果。</li></ol> <p>框架代码如下：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 引入依赖库</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> scipy<span class="token punctuation">.</span>special
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot

<span class="token comment"># 神经网络类定义</span>
<span class="token keyword">class</span> <span class="token class-name">neuralNetwork</span><span class="token punctuation">:</span>
    <span class="token comment"># 初始化神经网络</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>

    <span class="token comment"># 训练神经网络</span>
    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
   
    <span class="token comment"># 查询神经网络</span>
    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre></div><h4 id="初始化神经网络"><a href="#初始化神经网络" class="header-anchor">#</a> 初始化神经网络</h4> <p>接下来让我们进行第一步操作，初始化一个神经网络。</p> <div class="language-python extra-class"><pre class="language-python"><code>    <span class="token comment"># 初始化神经网络</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputnodes<span class="token punctuation">,</span> hiddennodes<span class="token punctuation">,</span> outputnodes<span class="token punctuation">,</span> learningrate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 设置输入层、隐藏层、输出层节点的数量</span>
        self<span class="token punctuation">.</span>inodes <span class="token operator">=</span> inputnodes
        self<span class="token punctuation">.</span>hnodes <span class="token operator">=</span> hiddennodes
        self<span class="token punctuation">.</span>onodes <span class="token operator">=</span> outputnodes
        
        <span class="token comment"># 连接权重，随机生成输入层到隐藏层和隐藏层到输出层的权重</span>
        self<span class="token punctuation">.</span>wih <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hnodes<span class="token punctuation">,</span> self<span class="token punctuation">.</span>inodes<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span>
        self<span class="token punctuation">.</span>who <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onodes<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hnodes<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span>

        <span class="token comment"># 学习率</span>
        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> learningrate
        
        <span class="token comment"># 将激活函数设置为 sigmoid 函数</span>
        self<span class="token punctuation">.</span>activation_function <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> scipy<span class="token punctuation">.</span>special<span class="token punctuation">.</span>expit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        
        <span class="token keyword">pass</span>
</code></pre></div><p><strong>生成权重</strong></p> <p>生成连接权重使用 <code>numpy</code> 函数库，该库支持大维度数组以及矩阵的运算，通过<code>numpy.random.rand(x, y)</code>可以快速生成一个 <code>x * y</code> 的矩阵，每个数字都是一个 0 ~ 1 的随机数。因为导入库的时候使用了 <code>import numpy as np</code> 命令，所有代码中可以用 <code>np</code> 来代替 <code>numpy</code>。</p> <p><img src="https://file.shenfq.com/FjWSNNZ758iVgqaGunY3LNYu60Iv.png" alt="image"></p> <p>上面就是通过 <code>numpy.random.rand</code> 方法生成一个 <code>3 * 3</code> 矩阵的案例。减去0.5是为了保证生成的权重所有权重都能维持在 -0.5 ~ 0.5 之间的一个随机值。</p> <p><img src="https://file.shenfq.com/FuGnOobiInRSl4F9PXOP_Odn-YPj.png" alt="image"></p> <p><strong>激活函数</strong></p> <p><code>scipy.special</code> 模块中包含了大量的函数库，利用 <code>scipy.special</code> 库可以很方便快捷的构造出一个激活函数：</p> <div class="language-python extra-class"><pre class="language-python"><code>activation_function <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> scipy<span class="token punctuation">.</span>special<span class="token punctuation">.</span>expit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre></div><h4 id="查询神经网络"><a href="#查询神经网络" class="header-anchor">#</a> 查询神经网络</h4> <div class="language-python extra-class"><pre class="language-python"><code>    <span class="token comment"># 查询神经网络    </span>
    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将输入的数组转化为一个二维数组</span>
        inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>inputs_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        
        <span class="token comment"># 计算输入数据与权重的点积</span>
        hidden_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>wih<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        <span class="token comment"># 经过激活函数的到隐藏层数据</span>
        hidden_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>hidden_inputs<span class="token punctuation">)</span>
        
        <span class="token comment"># 计算隐藏层数据与权重的点积</span>
        final_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">,</span> hidden_outputs<span class="token punctuation">)</span>
        <span class="token comment"># 最终到达输出层的数据</span>
        final_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>final_inputs<span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> final_outputs
</code></pre></div><p>查询神经网络的操作很简单，只需要使用 <code>numpy</code> 的 <code>dot</code> 方法对两个矩阵求点积即可。</p> <p>这里有一个知识点，就是关于 <code>numpy</code> 的数据类型，通过 <code>numpy.array</code> 方法能够将 python 中的数组转为一个 N 维数组对象 <code>Ndarray</code>，该方法第二个参数就是表示转化后的维度。</p> <p><img src="https://file.shenfq.com/FnfUXxYR0zUQaBWUxp8RNZXxBpbr.png" alt="image"></p> <p>上图是一个普通数组 <code>[1, 2, 3]</code> 使用该方法转变成二维数组，返回 <code>[[1, 2, 3]]</code>。该方法还有个属性 T，本质是调用 <code>numpy</code> 的 <code>transpose</code> 方法，对数组进行轴对换，如下图所示。</p> <p><img src="https://file.shenfq.com/FvmwZV-hOpFrG2uVrO3G-_nVgRCc.png" alt="image"></p> <p>通过转置我们就能得到一个合适的输入矩阵了。</p> <p><img src="https://file.shenfq.com/Fr4gSENAXsb-vwRuOkIc4OoIKT71.png" alt="image"></p> <p><img src="https://file.shenfq.com/Fjz5HdsAs_XNskbCwoyB8Q0-4laj.png" alt="image"></p> <h4 id="训练神经网络"><a href="#训练神经网络" class="header-anchor">#</a> 训练神经网络</h4> <div class="language-python extra-class"><pre class="language-python"><code>    <span class="token comment"># 训练神经网络</span>
    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs_list<span class="token punctuation">,</span> targets_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将输入数据与目标数据转为二维数组</span>
        inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>inputs_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        targets <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>targets_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
        
        <span class="token comment"># 通过矩阵点积和激活函数得到隐藏层的输出</span>
        hidden_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>wih<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        hidden_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>hidden_inputs<span class="token punctuation">)</span>
        
        <span class="token comment"># 通过矩阵点积和激活函数得到最终输出</span>
        final_inputs <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">,</span> hidden_outputs<span class="token punctuation">)</span>
        final_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>final_inputs<span class="token punctuation">)</span>
        
        <span class="token comment"># 获取目标值与实际值的差值</span>
        output_errors <span class="token operator">=</span> targets <span class="token operator">-</span> final_outputs
        <span class="token comment"># 反向传播差值</span>
        hidden_errors <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">.</span>T<span class="token punctuation">,</span> output_errors<span class="token punctuation">)</span> 
        
        <span class="token comment"># 通过梯度下降法更新隐藏层到输出层的权重</span>
        self<span class="token punctuation">.</span>who <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>output_errors <span class="token operator">*</span> final_outputs <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> final_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
            np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>hidden_outputs<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 通过梯度下降法更新输入层到隐藏层的权重</span>
        self<span class="token punctuation">.</span>wih <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>
            <span class="token punctuation">(</span>hidden_errors <span class="token operator">*</span> hidden_outputs <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> hidden_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
            np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token keyword">pass</span>
</code></pre></div><p>训练神经网络前半部分与查询类似，中间会将得到的差值通过求矩阵点积的方式进行反向传播，最后就是使用梯度下级的方法修正权重。其中 <code>self.lr</code> 为梯度下降的学习率，这个值是限制梯度方向的速率，我们需要经常调整这个值来达到模型的最优解。</p> <h3 id="进行训练"><a href="#进行训练" class="header-anchor">#</a> 进行训练</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 设置每一层的节点数量</span>
input_nodes <span class="token operator">=</span> <span class="token number">784</span>
hidden_nodes <span class="token operator">=</span> <span class="token number">100</span>
output_nodes <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment"># 学习率</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token comment"># 创建神经网络模型</span>
n <span class="token operator">=</span> neuralNetwork<span class="token punctuation">(</span>input_nodes<span class="token punctuation">,</span>hidden_nodes<span class="token punctuation">,</span>output_nodes<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>

<span class="token comment"># 加载训练数据</span>
training_data_file <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;datasets/mnist_train_100.csv&quot;</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
training_data_list <span class="token operator">=</span> training_data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
training_data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 训练神经网络</span>
<span class="token comment"># epochs 表示训练次数</span>
epochs <span class="token operator">=</span> <span class="token number">10</span>
<span class="token keyword">for</span> e <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 遍历所有数据进行训练</span>
    <span class="token keyword">for</span> record <span class="token keyword">in</span> training_data_list<span class="token punctuation">:</span>
        <span class="token comment"># 数据通过 ',' 分割，变成一个数组</span>
        all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>
        <span class="token comment"># 分离出图片的像素点到一个单独数组</span>
        inputs <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token number">0.99</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>
        <span class="token comment"># 创建目标输出值（数字 0~9 出现的概率，默认全部为 0.01）</span>
        targets <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_nodes<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>
        <span class="token comment"># all_values[0] 表示手写数字的真实值，将该数字的概率设为 0.99</span>
        targets<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.99</span>
        n<span class="token punctuation">.</span>train<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>
        <span class="token keyword">pass</span>
    <span class="token keyword">pass</span>

<span class="token comment"># 训练完毕</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'done'</span><span class="token punctuation">)</span>

</code></pre></div><h3 id="验证训练结果"><a href="#验证训练结果" class="header-anchor">#</a> 验证训练结果</h3> <div class="language-python extra-class"><pre class="language-python"><code>
<span class="token comment"># 加载测试数据</span>
test_data_file <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;datasets/mnist_test_10.csv&quot;</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
test_data_list <span class="token operator">=</span> test_data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
test_data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 测试神经网络</span>
<span class="token comment"># 记录所有的训练值，正确存 1 ，错误存 0 。</span>
scorecard <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment"># 遍历所有数据进行测试</span>
<span class="token keyword">for</span> record <span class="token keyword">in</span> test_data_list<span class="token punctuation">:</span>
    <span class="token comment"># 数据通过 ',' 分割，变成一个数组</span>
    all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>
    <span class="token comment"># 第一个数字为正确答案</span>
    correct_label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 取出测试的输入数据</span>
    inputs <span class="token operator">=</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token number">0.99</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>
    <span class="token comment"># 查询神经网络</span>
    outputs <span class="token operator">=</span> n<span class="token punctuation">.</span>query<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment"># 取出概率最大的数字，表示输出</span>
    label <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>
    <span class="token comment"># 打印出真实值与查询值</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'act: '</span><span class="token punctuation">,</span> label<span class="token punctuation">,</span> <span class="token string">' pre: '</span><span class="token punctuation">,</span> correct_label<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>label <span class="token operator">==</span> correct_label<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 神经网络查询结果与真实值匹配，记录数组存入 1</span>
        scorecard<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token comment"># 神经网络查询结果与真实值不匹配，记录数组存入 0</span>
        scorecard<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">pass</span>
    
    <span class="token keyword">pass</span>
    
<span class="token comment"># 计算训练的成功率</span>
scorecard_array <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>scorecard<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;performance = &quot;</span><span class="token punctuation">,</span> scorecard_array<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> scorecard_array<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
</code></pre></div><h3 id="完整代码"><a href="#完整代码" class="header-anchor">#</a> 完整代码</h3> <p>要查看完整代码可以访问我的 github： <a href="https://github.com/Shenfq/deep_neural_network/blob/master/NeuralNetWork.ipynb" target="_blank" rel="noopener noreferrer">deep_neural_network<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p>到这里整个深度神级网络的模型原理与实践已经全部进行完毕了，虽然有些部分概念讲解并不是那么仔细，但是你还可以通过搜索其他资料了解更多。感谢《Python神经网络编程》这本书，因为它才有了这个博客，如果感兴趣你也可以买来看看，这本书真的用很简单的语言描述了复杂的数学计算。</p> <p>人工智能现在确实是一个非常火热的阶段，希望感兴趣的同学们多多尝试，但是也不要一昧的追新，忘记了自己本来的优势。</p></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新时间: </span> <span class="time">10/8/2022, 8:09:00 AM</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-ac050c62><li class="level-2" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#理论基础" class="sidebar-link reco-side-理论基础" data-v-ac050c62>理论基础</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#什么是神经网络" class="sidebar-link reco-side-什么是神经网络" data-v-ac050c62>什么是神经网络</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#神经元如何输入输出" class="sidebar-link reco-side-神经元如何输入输出" data-v-ac050c62>神经元如何输入输出</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#矩阵乘法" class="sidebar-link reco-side-矩阵乘法" data-v-ac050c62>矩阵乘法</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#反向传播" class="sidebar-link reco-side-反向传播" data-v-ac050c62>反向传播</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#梯度下降" class="sidebar-link reco-side-梯度下降" data-v-ac050c62>梯度下降</a></li><li class="level-2" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#实战" class="sidebar-link reco-side-实战" data-v-ac050c62>实战</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#环境准备" class="sidebar-link reco-side-环境准备" data-v-ac050c62>环境准备</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#搭建神经网络" class="sidebar-link reco-side-搭建神经网络" data-v-ac050c62>搭建神经网络</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#进行训练" class="sidebar-link reco-side-进行训练" data-v-ac050c62>进行训练</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#验证训练结果" class="sidebar-link reco-side-验证训练结果" data-v-ac050c62>验证训练结果</a></li><li class="level-3" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#完整代码" class="sidebar-link reco-side-完整代码" data-v-ac050c62>完整代码</a></li><li class="level-2" data-v-ac050c62><a href="/posts/2019/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#总结" class="sidebar-link reco-side-总结" data-v-ac050c62>总结</a></li></ul></main></div> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/assets/js/app.318ac574.js" defer></script><script src="/assets/js/3.38c624e7.js" defer></script><script src="/assets/js/1.a547ec77.js" defer></script><script src="/assets/js/40.902ba1b5.js" defer></script>
  </body>
</html>
